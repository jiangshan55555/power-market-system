#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¿è¡Œæ‰€æœ‰é¢„æµ‹æ¨¡åž‹å¹¶è¿”å›žç»“æžœ
"""

import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.impute import SimpleImputer
import sys
from pathlib import Path

# æ·»åŠ åŽŸæ¥é¡¹ç›®çš„è·¯å¾„
ORIGINAL_PROJECT_PATH = Path(__file__).parent.parent.parent / 'power-market-system' / 'åŽŸæ¥çš„é¡¹ç›®èµ„æ–™'
sys.path.insert(0, str(ORIGINAL_PROJECT_PATH))

def run_all_models(data_with_features, price_column, time_column, feature_cols):
    """
    è¿è¡Œæ‰€æœ‰é¢„æµ‹æ¨¡åž‹ - å®Œå…¨æŒ‰ç…§åŽŸé¡¹ç›®çš„æ–¹å¼å®žçŽ°

    Args:
        data_with_features: åŒ…å«æ‰€æœ‰ç‰¹å¾çš„æ•°æ®æ¡†
        price_column: ç”µä»·åˆ—å
        time_column: æ—¶é—´åˆ—å
        feature_cols: ç‰¹å¾åˆ—ååˆ—è¡¨ï¼ˆåº”è¯¥æ˜¯5ä¸ªï¼šhour, dayofweek, day, price_lag1, price_lag4ï¼‰

    Returns:
        dict: åŒ…å«æ‰€æœ‰æ¨¡åž‹é¢„æµ‹ç»“æžœå’Œæ€§èƒ½æŒ‡æ ‡çš„å­—å…¸
    """
    print(f"\n{'='*60}")
    print(f"ðŸ¤– å¼€å§‹è¿è¡Œæ‰€æœ‰é¢„æµ‹æ¨¡åž‹ï¼ˆåŽŸé¡¹ç›®æ–¹å¼ï¼‰...")
    print(f"{'='*60}\n")

    # æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²ï¼šå‰80%è®­ç»ƒï¼ŒåŽ20%æµ‹è¯•
    split_idx = int(len(data_with_features) * 0.8)

    print(f"âœ… æ•°æ®åˆ†å‰²å®Œæˆ")
    print(f"   è®­ç»ƒé›†å¤§å°: {split_idx}")
    print(f"   æµ‹è¯•é›†å¤§å°: {len(data_with_features) - split_idx}")
    print(f"   ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {feature_cols}")

    # æå–ç‰¹å¾å’Œç›®æ ‡å€¼ï¼ˆä¸ä½¿ç”¨reset_indexï¼Œä¿æŒåŽŸå§‹ç´¢å¼•ï¼‰
    X = data_with_features[feature_cols].values
    y = data_with_features[price_column].values
    timestamps = pd.to_datetime(data_with_features[time_column])

    # ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    test_timestamps = timestamps[split_idx:]

    print(f"   è®­ç»ƒé›†æ—¶é—´èŒƒå›´: {timestamps.iloc[0]} åˆ° {timestamps.iloc[split_idx-1]}")
    print(f"   æµ‹è¯•é›†æ—¶é—´èŒƒå›´: {timestamps.iloc[split_idx]} åˆ° {timestamps.iloc[-1]}")

    # ä½¿ç”¨SimpleImputerå¤„ç†ç¼ºå¤±å€¼ï¼ˆåŽŸé¡¹ç›®çš„æ–¹å¼ï¼‰
    imputer = SimpleImputer(strategy='mean')
    X_train = imputer.fit_transform(X_train)
    X_test = imputer.transform(X_test)

    print(f"âœ… ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")
    
    # å­˜å‚¨æ‰€æœ‰æ¨¡åž‹çš„é¢„æµ‹ç»“æžœ
    all_predictions = {}
    all_metrics = {}
    
    # æ¨¡åž‹åˆ—è¡¨
    models_to_run = [
        ('historical', 'åŽ†å²åŒæœŸæ¨¡åž‹'),
        ('random_forest', 'éšæœºæ£®æž—'),
        ('linear_regression', 'çº¿æ€§å›žå½’'),
        ('gradient_boosting', 'æ¢¯åº¦æå‡'),
        ('xgboost', 'XGBoost'),
        ('ensemble', 'é›†æˆæ¨¡åž‹')
    ]
    
    # 1. åŽ†å²åŒæœŸæ¨¡åž‹ï¼ˆä¿®å¤ç‰ˆ - åªä½¿ç”¨è®­ç»ƒé›†æ•°æ®ï¼‰
    print(f"\n1ï¸âƒ£ è®­ç»ƒåŽ†å²åŒæœŸæ¨¡åž‹...")
    try:
        historical_pred = []
        train_timestamps = timestamps[:split_idx]

        for i, test_time in enumerate(test_timestamps):
            # åªä½¿ç”¨è®­ç»ƒé›†ä¸­ç›¸åŒå°æ—¶çš„æ•°æ®
            same_hour_mask = train_timestamps.hour == test_time.hour
            same_hour_values = y_train[same_hour_mask]

            if len(same_hour_values) > 0:
                historical_pred.append(np.mean(same_hour_values))
            else:
                historical_pred.append(np.mean(y_train))

        all_predictions['historical'] = np.array(historical_pred)
        all_metrics['historical'] = calculate_metrics(y_test, all_predictions['historical'])
        print(f"   âœ… åŽ†å²åŒæœŸæ¨¡åž‹å®Œæˆ - MAE: {all_metrics['historical']['mae']:.2f}")
    except Exception as e:
        print(f"   âŒ åŽ†å²åŒæœŸæ¨¡åž‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # 2. éšæœºæ£®æž—æ¨¡åž‹
    print(f"\n2ï¸âƒ£ è®­ç»ƒéšæœºæ£®æž—æ¨¡åž‹...")
    try:
        from src.predictions.random_forest_model import RandomForestModel
        
        rf_model = RandomForestModel(config={'HYPERPARAMETER_TUNING': {'CV_FOLDS': 3, 'RF_SEARCH_ITERATIONS': 5}})
        if rf_model.train(X_train, y_train):
            all_predictions['random_forest'] = rf_model.predict(X_test)
            all_metrics['random_forest'] = calculate_metrics(y_test, all_predictions['random_forest'])
            print(f"   âœ… éšæœºæ£®æž—æ¨¡åž‹å®Œæˆ - MAE: {all_metrics['random_forest']['mae']:.2f}")
        else:
            print(f"   âŒ éšæœºæ£®æž—æ¨¡åž‹è®­ç»ƒå¤±è´¥")
    except Exception as e:
        print(f"   âŒ éšæœºæ£®æž—æ¨¡åž‹å¤±è´¥: {e}")
    
    # 3. çº¿æ€§å›žå½’æ¨¡åž‹
    print(f"\n3ï¸âƒ£ è®­ç»ƒçº¿æ€§å›žå½’æ¨¡åž‹...")
    try:
        from src.predictions.linear_regression_model import LinearRegressionModel
        
        lr_model = LinearRegressionModel(config={'HYPERPARAMETER_TUNING': {'CV_FOLDS': 3, 'LINEAR_SEARCH_ITERATIONS': 5}})
        if lr_model.train(X_train, y_train):
            all_predictions['linear_regression'] = lr_model.predict(X_test)
            all_metrics['linear_regression'] = calculate_metrics(y_test, all_predictions['linear_regression'])
            print(f"   âœ… çº¿æ€§å›žå½’æ¨¡åž‹å®Œæˆ - MAE: {all_metrics['linear_regression']['mae']:.2f}")
        else:
            print(f"   âŒ çº¿æ€§å›žå½’æ¨¡åž‹è®­ç»ƒå¤±è´¥")
    except Exception as e:
        print(f"   âŒ çº¿æ€§å›žå½’æ¨¡åž‹å¤±è´¥: {e}")
    
    # 4. æ¢¯åº¦æå‡æ¨¡åž‹
    print(f"\n4ï¸âƒ£ è®­ç»ƒæ¢¯åº¦æå‡æ¨¡åž‹...")
    try:
        from src.predictions.gradient_boosting_model import GradientBoostingModel
        
        gb_model = GradientBoostingModel(config={'HYPERPARAMETER_TUNING': {'CV_FOLDS': 3, 'GB_SEARCH_ITERATIONS': 5}})
        if gb_model.train(X_train, y_train):
            all_predictions['gradient_boosting'] = gb_model.predict(X_test)
            all_metrics['gradient_boosting'] = calculate_metrics(y_test, all_predictions['gradient_boosting'])
            print(f"   âœ… æ¢¯åº¦æå‡æ¨¡åž‹å®Œæˆ - MAE: {all_metrics['gradient_boosting']['mae']:.2f}")
        else:
            print(f"   âŒ æ¢¯åº¦æå‡æ¨¡åž‹è®­ç»ƒå¤±è´¥")
    except Exception as e:
        print(f"   âŒ æ¢¯åº¦æå‡æ¨¡åž‹å¤±è´¥: {e}")
    
    # 5. XGBoostæ¨¡åž‹
    print(f"\n5ï¸âƒ£ è®­ç»ƒXGBoostæ¨¡åž‹...")
    try:
        from src.predictions.xgboost_model import XGBoostModel
        
        xgb_model = XGBoostModel(config={'HYPERPARAMETER_TUNING': {'CV_FOLDS': 3, 'XGB_SEARCH_ITERATIONS': 5}})
        if xgb_model.train(X_train, y_train):
            all_predictions['xgboost'] = xgb_model.predict(X_test)
            all_metrics['xgboost'] = calculate_metrics(y_test, all_predictions['xgboost'])
            print(f"   âœ… XGBoostæ¨¡åž‹å®Œæˆ - MAE: {all_metrics['xgboost']['mae']:.2f}")
        else:
            print(f"   âŒ XGBoostæ¨¡åž‹è®­ç»ƒå¤±è´¥")
    except Exception as e:
        print(f"   âŒ XGBoostæ¨¡åž‹å¤±è´¥: {e}")
    
    # 6. é›†æˆæ¨¡åž‹
    print(f"\n6ï¸âƒ£ ç”Ÿæˆé›†æˆæ¨¡åž‹é¢„æµ‹...")
    try:
        from src.predictions.ensemble_model import EnsembleModel
        
        ensemble_config = {
            'selection_method': 'top_k',
            'top_k': 4,
            'mae_threshold': 40.0,
            'rmse_threshold': 70.0,
            'r2_threshold': -0.2,
            'ensemble_method': 'weighted_average',
            'exclude_models': [],
            'min_models': 2,
        }
        
        ensemble_model = EnsembleModel(config=ensemble_config)
        ensemble_model.train(all_predictions, y_test)
        ensemble_pred = ensemble_model.predict()
        
        if ensemble_pred is not None:
            all_predictions['ensemble'] = ensemble_pred
            all_metrics['ensemble'] = calculate_metrics(y_test, ensemble_pred)
            print(f"   âœ… é›†æˆæ¨¡åž‹å®Œæˆ - MAE: {all_metrics['ensemble']['mae']:.2f}")
            ensemble_model.print_summary()
        else:
            print(f"   âŒ é›†æˆæ¨¡åž‹é¢„æµ‹å¤±è´¥")
    except Exception as e:
        print(f"   âŒ é›†æˆæ¨¡åž‹å¤±è´¥: {e}")
    
    print(f"\n{'='*60}")
    print(f"âœ… æ‰€æœ‰æ¨¡åž‹è¿è¡Œå®Œæˆï¼")
    print(f"{'='*60}\n")
    
    return {
        'predictions': all_predictions,
        'metrics': all_metrics,
        'y_test': y_test,
        'timestamps': test_timestamps
    }

def calculate_metrics(y_true, y_pred):
    """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    
    # è®¡ç®—MAPE (å¤„ç†é›¶å€¼)
    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true != 0, y_true, 1))) * 100
    
    # è®¡ç®—æ–¹å‘å‡†ç¡®çŽ‡
    if len(y_true) > 1:
        actual_diff = np.diff(y_true)
        pred_diff = np.diff(y_pred)
        direction_accuracy = np.mean((actual_diff * pred_diff) > 0) * 100
    else:
        direction_accuracy = 0.0
    
    return {
        'mae': float(mae),
        'rmse': float(rmse),
        'r2': float(r2),
        'mape': float(mape),
        'direction_accuracy': float(direction_accuracy)
    }

