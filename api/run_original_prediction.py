#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¿è¡ŒåŸé¡¹ç›®çš„é¢„æµ‹é€»è¾‘
ç›´æ¥è°ƒç”¨åŸé¡¹ç›® main_prediction.py çš„ main() å‡½æ•°
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import json

# æ·»åŠ åŸé¡¹ç›®è·¯å¾„
ORIGINAL_PROJECT_PATH = Path(__file__).parent.parent.parent / "power-market-system" / "åŸæ¥çš„é¡¹ç›®èµ„æ–™"
sys.path.insert(0, str(ORIGINAL_PROJECT_PATH))

def run_original_prediction():
    """
    ç›´æ¥è°ƒç”¨åŸé¡¹ç›® main_prediction.py çš„ main() å‡½æ•°

    Returns:
        dict: åŒ…å«é¢„æµ‹ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ ç›´æ¥è°ƒç”¨åŸé¡¹ç›® main_prediction.py...")
    print(f"{'='*60}\n")

    # ä¿å­˜å½“å‰å·¥ä½œç›®å½•
    original_cwd = os.getcwd()

    try:
        # åˆ‡æ¢åˆ°åŸé¡¹ç›®ç›®å½•
        os.chdir(ORIGINAL_PROJECT_PATH)
        print(f"âœ… åˆ‡æ¢å·¥ä½œç›®å½•åˆ°: {os.getcwd()}")

        # å¯¼å…¥åŸé¡¹ç›®çš„ main å‡½æ•°
        from src.main_prediction import main as original_main

        print("âœ… æˆåŠŸå¯¼å…¥åŸé¡¹ç›® main_prediction.py")

        # è°ƒç”¨åŸé¡¹ç›®çš„ main() å‡½æ•°
        print("\n" + "="*60)
        print("å¼€å§‹è¿è¡ŒåŸé¡¹ç›® main() å‡½æ•°...")
        print("="*60 + "\n")

        original_main()

        print("\n" + "="*60)
        print("âœ… åŸé¡¹ç›® main() å‡½æ•°æ‰§è¡Œå®Œæˆ")
        print("="*60 + "\n")

        # è¯»å–åŸé¡¹ç›®ç”Ÿæˆçš„é¢„æµ‹ç»“æœæ–‡ä»¶
        prediction_file = ORIGINAL_PROJECT_PATH / 'output' / 'predictions' / 'prediction_results.csv'

        if not prediction_file.exists():
            raise FileNotFoundError(f"é¢„æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {prediction_file}")

        print(f"\nğŸ“‚ è¯»å–é¢„æµ‹ç»“æœ: {prediction_file}")
        results_df = pd.read_csv(prediction_file)

        print(f"   ç»“æœæ•°æ®å½¢çŠ¶: {results_df.shape}")
        print(f"   åˆ—å: {results_df.columns.tolist()}")

        # è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶ä»¥è·å–æ—¶é—´æˆ³ï¼ˆéœ€è¦åˆå¹¶5æœˆå’Œ6æœˆçš„æ•°æ®ï¼‰
        raw_data_file_may = ORIGINAL_PROJECT_PATH / 'data' / 'rawdata_0501.xlsx'
        raw_data_file_jun = ORIGINAL_PROJECT_PATH / 'data' / 'rawdata_0601.xlsx'

        print(f"\nğŸ“‚ è¯»å–åŸå§‹æ•°æ®ä»¥è·å–æ—¶é—´æˆ³:")
        print(f"   5æœˆæ•°æ®: {raw_data_file_may}")
        print(f"   6æœˆæ•°æ®: {raw_data_file_jun}")

        raw_df_may = pd.read_excel(raw_data_file_may)
        raw_df_jun = pd.read_excel(raw_data_file_jun)

        # ç»Ÿä¸€ä½¿ç”¨"æ—¥æœŸ"åˆ—ä½œä¸ºæ—¶é—´æˆ³ï¼ˆåŒ…å«å®Œæ•´çš„æ—¥æœŸå’Œæ—¶é—´ï¼‰
        # 5æœˆæ•°æ®çš„"æ—¶é—´"åˆ—æœ‰å®Œæ•´æ—¥æœŸæ—¶é—´ï¼Œ6æœˆæ•°æ®çš„"æ—¶é—´"åˆ—åªæœ‰æ—¶é—´
        # ä½†ä¸¤ä¸ªæ–‡ä»¶éƒ½æœ‰"æ—¥æœŸ"åˆ—åŒ…å«å®Œæ•´çš„æ—¥æœŸæ—¶é—´
        for df, month_name in [(raw_df_may, '5æœˆ'), (raw_df_jun, '6æœˆ')]:
            if 'æ—¥æœŸ' in df.columns:
                # ä½¿ç”¨"æ—¥æœŸ"åˆ—æ›¿æ¢"æ—¶é—´"åˆ—
                df['æ—¶é—´'] = df['æ—¥æœŸ']
                print(f"   âœ… {month_name}æ•°æ®ä½¿ç”¨'æ—¥æœŸ'åˆ—ä½œä¸ºæ—¶é—´æˆ³ï¼Œç¤ºä¾‹: {df['æ—¶é—´'].iloc[0]}")

        # åˆå¹¶ä¸¤ä¸ªæœˆçš„æ•°æ®
        raw_df = pd.concat([raw_df_may, raw_df_jun], ignore_index=True)

        # è®¡ç®—æµ‹è¯•é›†çš„èµ·å§‹ç´¢å¼•ï¼ˆå‡è®¾80/20åˆ†å‰²ï¼‰
        total_samples = len(raw_df)
        train_size = int(total_samples * 0.8)
        test_size = total_samples - train_size

        print(f"   5æœˆæ•°æ®: {len(raw_df_may)} æ¡")
        print(f"   6æœˆæ•°æ®: {len(raw_df_jun)} æ¡")
        print(f"   åˆå¹¶åæ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"   è®­ç»ƒé›†å¤§å°: {train_size}")
        print(f"   æµ‹è¯•é›†å¤§å°: {test_size}")
        print(f"   é¢„æµ‹ç»“æœæ•°é‡: {len(results_df)}")

        # ä»åŸå§‹æ•°æ®ä¸­æå–æ—¶é—´æˆ³
        # ç”±äºé¢„æµ‹ç»“æœçš„ timestamp åˆ—æ˜¯ç©ºçš„ï¼Œæˆ‘ä»¬éœ€è¦ä»åŸå§‹æ•°æ®ä¸­æå–
        test_timestamps = []

        # æ£€æŸ¥é¢„æµ‹ç»“æœçš„ timestamp åˆ—æ˜¯å¦æœ‰æ•ˆ
        has_valid_timestamps = False
        if 'timestamp' in results_df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰éç©ºä¸”éç©ºå­—ç¬¦ä¸²çš„æ—¶é—´æˆ³
            # æ³¨æ„ï¼šç©ºå­—ç¬¦ä¸² '' ä¸ä¼šè¢« notna() è¯†åˆ«ä¸ºç¼ºå¤±å€¼
            valid_count = 0
            for ts in results_df['timestamp']:
                if pd.notna(ts) and str(ts).strip() != '':
                    valid_count += 1

            # è¦æ±‚è‡³å°‘ 80% çš„æ—¶é—´æˆ³æœ‰æ•ˆæ‰ä½¿ç”¨é¢„æµ‹ç»“æœçš„ timestamp åˆ—
            valid_ratio = valid_count / len(results_df) if len(results_df) > 0 else 0
            print(f"   ğŸ“Š é¢„æµ‹ç»“æœä¸­æœ‰ {valid_count}/{len(results_df)} ä¸ªæœ‰æ•ˆæ—¶é—´æˆ³ ({valid_ratio:.1%})")

            if valid_ratio >= 0.8:
                has_valid_timestamps = True
                print(f"   âœ… æ—¶é—´æˆ³æœ‰æ•ˆç‡ >= 80%ï¼Œå°†ä½¿ç”¨é¢„æµ‹ç»“æœçš„ timestamp åˆ—")
            else:
                print(f"   âš ï¸ æ—¶é—´æˆ³æœ‰æ•ˆç‡ < 80%ï¼Œå°†ä»åŸå§‹æ•°æ®æå–æ—¶é—´æˆ³")

        if has_valid_timestamps:
            # å¦‚æœé¢„æµ‹ç»“æœä¸­æœ‰æœ‰æ•ˆçš„ timestamp åˆ—ï¼Œç›´æ¥ä½¿ç”¨
            for ts in results_df['timestamp']:
                if pd.isna(ts) or ts == '':
                    test_timestamps.append('')
                elif isinstance(ts, pd.Timestamp):
                    test_timestamps.append(ts.strftime('%Y-%m-%d %H:%M'))
                else:
                    test_timestamps.append(str(ts))
            print(f"   âœ… ä»é¢„æµ‹ç»“æœçš„ timestamp åˆ—æå–æ—¶é—´æˆ³")
        else:
            # ä»åŸå§‹æ•°æ®æå–æ—¶é—´æˆ³
            # å–æœ€å len(results_df) æ¡æ•°æ®çš„æ—¶é—´æˆ³
            total_samples = len(raw_df)
            start_idx = total_samples - len(results_df)

            print(f"   ğŸ“Š åŸå§‹æ•°æ®æ€»æ ·æœ¬æ•°: {total_samples}")
            print(f"   ğŸ“Š é¢„æµ‹ç»“æœæ•°é‡: {len(results_df)}")
            print(f"   ğŸ“Š æå–æ—¶é—´æˆ³èŒƒå›´: [{start_idx}, {total_samples})")

            test_timestamps_raw = raw_df['æ—¶é—´'].iloc[start_idx:total_samples]
            for ts in test_timestamps_raw:
                if pd.isna(ts):
                    test_timestamps.append('')
                elif isinstance(ts, pd.Timestamp):
                    test_timestamps.append(ts.strftime('%Y-%m-%d %H:%M'))
                else:
                    # å°è¯•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
                    try:
                        ts_parsed = pd.to_datetime(ts)
                        test_timestamps.append(ts_parsed.strftime('%Y-%m-%d %H:%M'))
                    except:
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå­—ç¬¦ä¸²
                        test_timestamps.append(str(ts))
            print(f"   âœ… ä»åŸå§‹æ•°æ®æå–æ—¶é—´æˆ³ï¼ˆé¢„æµ‹ç»“æœä¸­æ— æœ‰æ•ˆ timestampï¼‰")

        print(f"   æ—¶é—´æˆ³æ•°é‡: {len(test_timestamps)}")
        print(f"   é¢„æµ‹ç»“æœæ•°é‡: {len(results_df)}")
        print(f"   æ—¶é—´æˆ³ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰: {test_timestamps[:3] if len(test_timestamps) >= 3 else test_timestamps}")
        print(f"   æ—¶é—´æˆ³ç¤ºä¾‹ï¼ˆå3ä¸ªï¼‰: {test_timestamps[-3:] if len(test_timestamps) >= 3 else test_timestamps}")

        # æå–æ•°æ®
        # åŸé¡¹ç›®è¾“å‡ºçš„åˆ—åæ˜¯è‹±æ–‡çš„: timestamp, actual, historical, random_forest, etc.
        y_test = results_df['actual'].values

        # æå–æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹å€¼
        predictions = {}
        model_columns = {
            'historical': 'historical',
            'random_forest': 'random_forest',
            'linear_regression': 'linear_regression',
            'gradient_boosting': 'gradient_boosting',
            'xgboost': 'xgboost',
            'ensemble': 'ensemble'
        }

        for model_key, col_name in model_columns.items():
            if col_name in results_df.columns:
                predictions[model_key] = results_df[col_name].values

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

        metrics = {}
        for model_name, pred in predictions.items():
            mae = mean_absolute_error(y_test, pred)
            rmse = np.sqrt(mean_squared_error(y_test, pred))
            r2 = r2_score(y_test, pred)

            # MAPE
            mape = np.mean(np.abs((y_test - pred) / np.where(y_test != 0, y_test, 1))) * 100

            # æ–¹å‘å‡†ç¡®ç‡
            if len(y_test) > 1:
                actual_diff = np.diff(y_test)
                pred_diff = np.diff(pred)
                direction_accuracy = np.mean((actual_diff * pred_diff) > 0) * 100
            else:
                direction_accuracy = 0.0

            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æœ‰æ•ˆçš„ JSON æ•°å€¼ï¼ˆå¤„ç† NaN å’Œ Infinityï¼‰
            def safe_float(value):
                """å°†å€¼è½¬æ¢ä¸ºå®‰å…¨çš„æµ®ç‚¹æ•°ï¼Œå¤„ç† NaN å’Œ Infinity"""
                if np.isnan(value) or np.isinf(value):
                    return None
                return float(value)

            metrics[model_name] = {
                'mae': safe_float(mae),
                'rmse': safe_float(rmse),
                'r2': safe_float(r2),
                'mape': safe_float(mape),
                'direction_accuracy': safe_float(direction_accuracy)
            }

            print(f"ğŸ“Š {model_name}: MAE={mae:.2f}, RMSE={rmse:.2f}, RÂ²={r2:.4f}")

        # å¤„ç† NaN å€¼çš„è¾…åŠ©å‡½æ•°
        def clean_array(arr):
            """å°†æ•°ç»„ä¸­çš„ NaN å’Œ Infinity æ›¿æ¢ä¸º None"""
            return [None if (isinstance(x, float) and (np.isnan(x) or np.isinf(x))) else x for x in arr]

        # è¿”å›ç»“æœ
        return {
            'success': True,
            'predictions': {k: clean_array(v.tolist()) for k, v in predictions.items()},
            'metrics': metrics,
            'y_test': clean_array(y_test.tolist()),
            'timestamps': test_timestamps,  # ä»åŸå§‹æ•°æ®ä¸­æå–çš„æ—¶é—´æˆ³
            'train_size': train_size,
            'test_size': test_size,
            'feature_names': ['hour', 'dayofweek', 'day', 'price_lag1', 'price_lag4']
        }

    except Exception as e:
        import traceback
        error_msg = f"é¢„æµ‹å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }
    finally:
        # æ¢å¤åŸå·¥ä½œç›®å½•
        os.chdir(original_cwd)
        print(f"âœ… æ¢å¤å·¥ä½œç›®å½•åˆ°: {os.getcwd()}")

